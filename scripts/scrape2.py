#!/usr/bin/env python
#Import the same libraries from our first script

#create a base_url that is just the domain and the directories that don't change

#create a new_page variable with the html page name

#concatenate the base_url and new_page into a url variable

#make a get request

#assign the r.content to html

#make a soup out of the html

#grab the body text. This is all the same as before

#pluck out the table from the body_text and assign it to "our_table"

#find our first tr and assign it to headers

#make an empty list that will hold our header names

#make a for loop and append all the text of all the 'th' tags to the myheaders list

#print myheaders out, so you can see how they differ

#create an output file name

#open the f file object

#create a w writer object

#write our header rows to the csv using w

#grab all the trs after the first in our_table and loop through them
#rename the variables in the right order and add new ones for offensedate, for instance












    #gather all the variables into a list

    #write the list to the csv with w


#close your f file object


